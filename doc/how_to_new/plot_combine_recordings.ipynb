{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Combine recordings in SpikeInterface\n\nIn this tutorial, we will walk through combining multiple recording objects. Sometimes this occurs due to hardware\nsettings (e.g., Intan software has a default setting of new files every 1 minute) or the experimenter decides to\nsplit their recording into multiple files for different experimental conditions. If the probe has not been moved,\nhowever, then during sorting it would likely make sense to combine these individual recording objects into one\nrecording object.\n\n## Why Combine?\n\nCombining your data into a single recording allows you to have consistent labels (`unit_ids`) across the whole recording.\n\nSpike sorters seek to sort spikes within a recording into groups of units. Thus if multiple `Recording` objects have the\nexact same probe location within some tissue and are occurring continuously in time, the units between the `Recordings` will\nbe the same. But if we sort each recording separately, the unit ids given by the sorter will not be the same between each\n`Sorting`, and so we will need extensive post-processing to try to figure out which units are actually the same between\neach `Sorting`. By combining everything into one `Recording`, all spikes will be sorted into the same pool of units.\n\n## Combining recordings continuous in time\n\nSome file formats (e.g., Intan) automatically create new files every minute or few minutes (with a setting that can be user\ncontrolled). Other times an experimenter separates their recording for experimental reasons. SpikeInterface provides two\ntools for bringing together these files into one `Recording` object.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concatenating Recordings\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First, let's cover concatenating recordings together. This will generate a mono-segment\n# recording object. Let's load a set of Intan files. 0 is the amplifier data for Intan\n\nimport spikeinterface as si  # This is only core\nimport spikeinterface.extractors as se\n\nrecording_one, _ = si.generate_ground_truth_recording(durations=[25])\nrecording_two, _ = si.generate_ground_truth_recording(durations=[25])\n\nprint(recording_one)\n\nprint(recording_two)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will concatenate these recordings together.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "concatenated_recording = si.concatenate_recordings([recording_one, recording_two])\n\nprint(concatenated_recording)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we know that we will deal with a lot of files, we can actually work our\nway through a series of them relatively quickly by doing\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "list_of_recs = [si.generate_ground_truth_recording(durations=[25])[0] for _ in range(4)]\nlist_of_recordings = []\nfor rec in list_of_recs:\n    list_of_recordings.append(rec)\nrecording = si.concatenate_recordings(list_of_recordings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Append Recordings\n\nIf you wish to keep each recording as a separate segment identity (e.g. if doing baseline, stim, poststim) you can use\n`append` instead of `concatenate`. This has the benefit of allowing you to keep different parts of data\nseparate, but it is important to note that not all sorters can handle multi-segment objects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "recording = si.append_recordings([recording_one, recording_two])\n\nprint(recording)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pitfalls\n\nIt's important to remember that these operations are directional. So:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "recording_forward = si.concatenate_recordings([recording_one, recording_two])\nrecording_backward = si.concatenate_recordings([recording_two, recording_one])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is important because your spike times will be relative to the start of your recording.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
